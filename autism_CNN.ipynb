{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "from random import shuffle \n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR1 = r'\\autism\\5kImages\\train\\autistic'\n",
    "TRAIN_DIR2 = r'\\autism\\5kImages\\train\\non_autistic'\n",
    "VALIDATION_DIR1 = r'\\autism\\5kImages\\valid\\autistic'\n",
    "VALIDATION_DIR2 = r'\\autism\\5kImages\\valid\\non_autistic'\n",
    "TEST_DIR1 = r'\\autism\\5kImages\\test\\autistic'\n",
    "TEST_DIR2 = r'\\autism\\5kImages\\test\\non_autistic'\n",
    "IMG_Resolution = 224\n",
    "LR = 1e-3\n",
    "training_data=[]\n",
    "test_data=[]\n",
    "validation_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def displayImage(img):\n",
    "   # cv.namedWindow(\"PALASH\", cv.WINDOW_NORMAL)\n",
    "   # cv.resizeWindow(\"PALASH\", 200, 200)\n",
    "    cv.imshow(\"PALASH\", img)\n",
    "    cv.waitKey(10)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "def create_data(dataList,path1, path2):\n",
    "   \n",
    "    for imgName in tqdm(os.listdir(path1)):   #first load autistic images\n",
    "        label=[1,0]        #[1,0] for autistic part   \n",
    "        fullpath=path1+'\\\\'+imgName       \n",
    "       # print(fullpath)\n",
    "        imgData = cv.imread(fullpath, cv.IMREAD_GRAYSCALE)   \n",
    "       # displayImage(imgData)\n",
    "        #print(imgData.shape)\n",
    "        dataList.append([np.array(imgData), np.array(label)]) \n",
    "    print(len(dataList))\n",
    "    for imgName in tqdm(os.listdir(path2)):   #first load autistic images\n",
    "        label=[0,1]        #[1,0] for autistic part   \n",
    "        fullpath=path2+'\\\\'+imgName       \n",
    "       # print(fullpath)\n",
    "        imgData = cv.imread(fullpath, cv.IMREAD_GRAYSCALE)   \n",
    "       # displayImage(imgData)\n",
    "        dataList.append([np.array(imgData), np.array(label)])    \n",
    "    shuffle(dataList)     \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process():\n",
    "    cwd = os.getcwd()\n",
    "    trpath1=cwd+TRAIN_DIR1 #autistic images\n",
    "    trpath2=cwd+TRAIN_DIR2 #regular images\n",
    "    vpath1=cwd+VALIDATION_DIR1 #autistic images\n",
    "    vpath2=cwd+VALIDATION_DIR2 #regular images\n",
    "    tstpath1=cwd+TEST_DIR1 #autistic images\n",
    "    tstpath2=cwd+TEST_DIR2 #regular images\n",
    "    #print(path)\n",
    "\n",
    "    create_data(training_data,trpath1,trpath2)\n",
    "    print(\"trainDataLen:\",len(training_data))\n",
    "    #np.save('train_data.npy', training_data) \n",
    "    \n",
    "   \n",
    "    create_data(validation_data,vpath1,vpath2)\n",
    "    print(\"ValidationDataLen:\",len(validation_data))\n",
    "    #np.save('validation_data.npy', validation_data) \n",
    "    \n",
    "  \n",
    "    create_data(test_data,tstpath1,tstpath2)\n",
    "    print(\"testDataLen:\",len(test_data))\n",
    "    #np.save('test_data.npy', test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data_arr[0][0]) #features of image 1\n",
    "#print(train_data_arr[0][1])  #lable of image1\n",
    "\n",
    "def main():\n",
    "    #data_process()\n",
    "    \n",
    "    train_x = np.array([i[0] for i in training_data]).reshape(-1, IMG_Resolution, IMG_Resolution, 1) \n",
    "    train_y = [i[1] for i in training_data] \n",
    "    validation_x = np.array([i[0] for i in validation_data]) \n",
    "    validation_y = [i[1] for i in validation_data] \n",
    "    test_x = np.array([i[0] for i in test_data]).reshape(-1, IMG_Resolution, IMG_Resolution, 1) \n",
    "    test_y = [i[1] for i in test_data] \n",
    "    print(train_x.ndim)\n",
    "    print(train_y[0])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_37",
   "language": "python",
   "name": "deep_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
